{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/twitter_MBTI.csv'\n",
    "\n",
    "\n",
    "data = pd.read_csv(data_path,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /storage/hhbao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /storage/hhbao/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /storage/hhbao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /storage/hhbao/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /storage/hhbao/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "nltk_stopwords.remove('no')\n",
    "nltk_stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "punctuation_translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(s, lowercase=True, remove_stopwords=True, remove_punctuation=True, stemmer=None, lemmatizer=None):\n",
    "    tokens = word_tokenize(s)\n",
    "\n",
    "    if lemmatizer is not None:\n",
    "        tokens = lemmatize_tokens(lemmatizer, tokens)\n",
    "    elif stemmer is not None:\n",
    "        tokens = stem_tokens(stemmer, tokens)\n",
    "\n",
    "    if lowercase:\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        tokens = [token for token in tokens if not token in nltk_stopwords]\n",
    "    \n",
    "    # Remove all punctuation marks if needed (note: also converts, e.g, \"Mr.\" to \"Mr\")\n",
    "    if remove_punctuation:\n",
    "        tokens = [ ''.join(c for c in s if c not in string.punctuation) for s in tokens ]\n",
    "        tokens = [ token for token in tokens if len(token) > 0 ] # Remove \"empty\" tokens\n",
    "\n",
    "    # if (len(tokens) == 0):\n",
    "    #     print('len = 0: '+ s)\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    return s.translate(punctuation_translator)\n",
    "\n",
    "def lemmatize_tokens(lemmatizer, tokens):\n",
    "    pos_tag_list = pos_tag(tokens)\n",
    "    for idx, (token, tag) in enumerate(pos_tag_list):\n",
    "        tag_simple = tag[0].lower() # Converts, e.g., \"VBD\" to \"c\"\n",
    "        if tag_simple in ['n', 'v', 'j']:\n",
    "            word_type = tag_simple.replace('j', 'a') \n",
    "        else:\n",
    "            word_type = 'n'\n",
    "        lemmatized_token = lemmatizer.lemmatize(token, pos=word_type)\n",
    "        tokens[idx] = lemmatized_token\n",
    "    return tokens\n",
    "\n",
    "def stem_tokens(stemmer, tokens):\n",
    "    for idx, token in enumerate(tokens):\n",
    "        tokens[idx] = stemmer.stem(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ie'] = data['label'].apply(lambda x: x[0])\n",
    "data['ns'] = data['label'].apply(lambda x: x[1])\n",
    "data['ft'] = data['label'].apply(lambda x: x[2])\n",
    "data['pj'] = data['label'].apply(lambda x: x[3])\n",
    "\n",
    "\n",
    "train_data, test_and_valid_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "valid_data, test_data = train_test_split(test_and_valid_data, test_size=0.5, random_state=42)\n",
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "\n",
    "content = train_data.iloc[:,1]\n",
    "content = [ preprocess_text(x, remove_stopwords=True, remove_punctuation=True, lemmatizer=wordnet_lemmatizer) for x in content ]\n",
    "\n",
    "X = vectorizer.fit_transform(content)\n",
    "Y_i = train_data.iloc[:,3]\n",
    "Y_n = train_data.iloc[:,4]\n",
    "Y_f = train_data.iloc[:,5]\n",
    "Y_p = train_data.iloc[:,6]\n",
    "\n",
    "\n",
    "Y_test_i = test_data.iloc[:,3]\n",
    "Y_test_n = test_data.iloc[:,4]\n",
    "Y_test_f = test_data.iloc[:,5]\n",
    "Y_test_p = test_data.iloc[:,6]\n",
    "X_test_content = test_data.iloc[:,1]\n",
    "X_test_content = [ preprocess_text(x, remove_stopwords=True, remove_punctuation=True, lemmatizer=wordnet_lemmatizer) for x in X_test_content ]\n",
    "\n",
    "X_test = vectorizer.transform(X_test_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e     0.6071    0.1283    0.2118       265\n",
      "           i     0.6818    0.9574    0.7965       517\n",
      "\n",
      "    accuracy                         0.6765       782\n",
      "   macro avg     0.6445    0.5429    0.5041       782\n",
      "weighted avg     0.6565    0.6765    0.5983       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(multi_class = 'multinomial',solver='newton-cg',max_iter = 1000).fit(X, Y_i)\n",
    "Y_lr_predict = lr_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_i, Y_lr_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n     0.7913    0.9984    0.8829       619\n",
      "           s     0.0000    0.0000    0.0000       163\n",
      "\n",
      "    accuracy                         0.7903       782\n",
      "   macro avg     0.3956    0.4992    0.4414       782\n",
      "weighted avg     0.6264    0.7903    0.6988       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(multi_class = 'multinomial',solver='newton-cg',max_iter = 1000).fit(X, Y_n)\n",
    "Y_lr_predict = lr_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_n, Y_lr_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f     0.6656    0.8681    0.7535       470\n",
      "           t     0.6331    0.3429    0.4449       312\n",
      "\n",
      "    accuracy                         0.6586       782\n",
      "   macro avg     0.6494    0.6055    0.5992       782\n",
      "weighted avg     0.6526    0.6586    0.6304       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(multi_class = 'multinomial',solver='newton-cg',max_iter = 1000).fit(X, Y_f)\n",
    "Y_lr_predict = lr_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_f, Y_lr_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           j     0.6915    0.5718    0.6260       341\n",
      "           p     0.7080    0.8027    0.7524       441\n",
      "\n",
      "    accuracy                         0.7020       782\n",
      "   macro avg     0.6997    0.6873    0.6892       782\n",
      "weighted avg     0.7008    0.7020    0.6973       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(multi_class = 'multinomial',solver='newton-cg',max_iter = 1000).fit(X, Y_p)\n",
    "Y_lr_predict = lr_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_p, Y_lr_predict, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e     0.0000    0.0000    0.0000       265\n",
      "           i     0.6611    1.0000    0.7960       517\n",
      "\n",
      "    accuracy                         0.6611       782\n",
      "   macro avg     0.3306    0.5000    0.3980       782\n",
      "weighted avg     0.4371    0.6611    0.5263       782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_fast/hhbao/anaconda/envs/llama/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/storage_fast/hhbao/anaconda/envs/llama/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/storage_fast/hhbao/anaconda/envs/llama/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes \n",
    "mnb_classifier = MultinomialNB().fit(X, Y_i)\n",
    "Y_predict = mnb_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_i, Y_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n     0.7916    1.0000    0.8837       619\n",
      "           s     0.0000    0.0000    0.0000       163\n",
      "\n",
      "    accuracy                         0.7916       782\n",
      "   macro avg     0.3958    0.5000    0.4418       782\n",
      "weighted avg     0.6266    0.7916    0.6995       782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_fast/hhbao/anaconda/envs/llama/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/storage_fast/hhbao/anaconda/envs/llama/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/storage_fast/hhbao/anaconda/envs/llama/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes \n",
    "mnb_classifier = MultinomialNB().fit(X, Y_n)\n",
    "Y_predict = mnb_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_n, Y_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f     0.6021    0.9979    0.7510       470\n",
      "           t     0.6667    0.0064    0.0127       312\n",
      "\n",
      "    accuracy                         0.6023       782\n",
      "   macro avg     0.6344    0.5021    0.3818       782\n",
      "weighted avg     0.6278    0.6023    0.4564       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes \n",
    "mnb_classifier = MultinomialNB().fit(X, Y_f)\n",
    "Y_predict = mnb_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_f, Y_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           j     0.8235    0.0411    0.0782       341\n",
      "           p     0.5725    0.9932    0.7264       441\n",
      "\n",
      "    accuracy                         0.5780       782\n",
      "   macro avg     0.6980    0.5171    0.4023       782\n",
      "weighted avg     0.6820    0.5780    0.4437       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes \n",
    "mnb_classifier = MultinomialNB().fit(X, Y_p)\n",
    "Y_predict = mnb_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_p, Y_predict, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e     0.5830    0.5962    0.5896       265\n",
      "           i     0.7906    0.7814    0.7860       517\n",
      "\n",
      "    accuracy                         0.7187       782\n",
      "   macro avg     0.6868    0.6888    0.6878       782\n",
      "weighted avg     0.7203    0.7187    0.7194       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_classifier = tree.DecisionTreeClassifier().fit(X, Y_i)\n",
    "Y_tree_predict = tree_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_i, Y_tree_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n     0.8633    0.8368    0.8499       619\n",
      "           s     0.4451    0.4969    0.4696       163\n",
      "\n",
      "    accuracy                         0.7660       782\n",
      "   macro avg     0.6542    0.6669    0.6597       782\n",
      "weighted avg     0.7761    0.7660    0.7706       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_classifier = tree.DecisionTreeClassifier().fit(X, Y_n)\n",
    "Y_tree_predict = tree_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_n, Y_tree_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f     0.7336    0.7617    0.7474       470\n",
      "           t     0.6190    0.5833    0.6007       312\n",
      "\n",
      "    accuracy                         0.6905       782\n",
      "   macro avg     0.6763    0.6725    0.6740       782\n",
      "weighted avg     0.6879    0.6905    0.6888       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_classifier = tree.DecisionTreeClassifier().fit(X, Y_f)\n",
    "Y_tree_predict = tree_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_f, Y_tree_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           j     0.6295    0.6628    0.6457       341\n",
      "           p     0.7281    0.6984    0.7130       441\n",
      "\n",
      "    accuracy                         0.6829       782\n",
      "   macro avg     0.6788    0.6806    0.6793       782\n",
      "weighted avg     0.6851    0.6829    0.6836       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_classifier = tree.DecisionTreeClassifier().fit(X, Y_p)\n",
    "Y_tree_predict = tree_classifier.predict(X_test)\n",
    "print(classification_report(Y_test_p, Y_tree_predict, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_fast/hhbao/anaconda/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Bert\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {\n",
    "        'i': 0,\n",
    "        'e': 1\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['ie']]\n",
    "        # self.labels = [label for label in df['Label']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "    # Get the labels\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    # Get the batch's labels\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    # Data Preparation\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=32)\n",
    "\n",
    "    # Cuda\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # Loss & Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:51<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.021 | Train Accuracy:  0.662 | Val Loss:  0.020 | Val Accuracy:  0.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.020 | Train Accuracy:  0.670 | Val Loss:  0.021 | Val Accuracy:  0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.020 | Train Accuracy:  0.672 | Val Loss:  0.021 | Val Accuracy:  0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.020 | Train Accuracy:  0.672 | Val Loss:  0.021 | Val Accuracy:  0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.020 | Train Accuracy:  0.673 | Val Loss:  0.021 | Val Accuracy:  0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.020 | Train Accuracy:  0.673 | Val Loss:  0.020 | Val Accuracy:  0.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.019 | Train Accuracy:  0.673 | Val Loss:  0.021 | Val Accuracy:  0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.019 | Train Accuracy:  0.673 | Val Loss:  0.021 | Val Accuracy:  0.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.019 | Train Accuracy:  0.676 | Val Loss:  0.021 | Val Accuracy:  0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.019 | Train Accuracy:  0.675 | Val Loss:  0.022 | Val Accuracy:  0.671\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 \n",
    "np.random.seed(42)\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, train_data, valid_data, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.660\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:49<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.021 | Train Accuracy:  0.652 | Val Loss:  0.021 | Val Accuracy:  0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.020 | Train Accuracy:  0.673 | Val Loss:  0.021 | Val Accuracy:  0.671\n",
      "Test Accuracy:  0.661\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "np.random.seed(42)\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, train_data, valid_data, LR, EPOCHS)\n",
    "evaluate(model, test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
